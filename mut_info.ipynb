{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mutual information score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Consider the following: X is a set of predicted classes(labels), Y is a set of true classes. $p_X(x)$ is probability of point to be predicted as class X=x, $p_Y(y)$ is probability of point to be of class Y=y, $p_{X,Y}(x,y)$ is probability of predicting class to be x and being y in reality ($p_X(x)$ and $p_Y(y)$ are marginal distributions of predicted and true classes, $p_{X,Y}(x,y)$ is their joint distribution). Then their mutual information is calculated as follows.<br>\n",
    "#### $I(X,Y) = \\sum_{x \\in X} \\sum_{y \\in Y} p_{X,Y}(x,y) \\log \\frac{p_{X,Y}(x,y)}{p_X(x)p_Y(Y)} = $ $ // p_X(x) = \\frac{|x|}{N}$, $p_y = \\frac{|y|}{N}$, $p_{X,Y}(x,y) = \\frac{|x \\cap y|}{N}//$ $ = \\sum_{x \\in X} \\sum_{y \\in Y} \\frac{|x \\cap y|}{N} \\log \\frac{N |x \\cap y|}{|x||y|}$ <br>\n",
    "#### Given predcited labels and corresponding true labels mutual information can be easily calculated using contingency matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the mutual information score between true labels and predicted labels using sklearn's contingency_matrix.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (ndarray): True labels.\n",
    "    y_pred (ndarray): Predicted labels.\n",
    "\n",
    "    Returns:\n",
    "    float: Mutual information score.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics.cluster import contingency_matrix\n",
    "    from numpy import log\n",
    "    contingency = contingency_matrix(y_true, y_pred)\n",
    "    ni = contingency.sum(axis=1)\n",
    "    nj = contingency.sum(axis=0)\n",
    "    N = contingency.sum()\n",
    "\n",
    "    mi = 0.0\n",
    "    for i in range(contingency.shape[0]):\n",
    "        for j in range(contingency.shape[1]):\n",
    "            if contingency[i, j]: mi += (contingency[i, j] / N) * log((N * contingency[i, j]) / (ni[i] * nj[j]))\n",
    "    return mi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([0, 0, 1, 1, 1, 2, 2, 2, 1])\n",
    "y_true = np.array([0, 0, 1, 1, 1, 2, 2, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert abs(mutual_information(y_true, y_pred) - mutual_info_score(y_true, y_pred)) < 1e-5,\\\n",
    "            \"Implemented MI is not the same as sci-kit learn one!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for symmetry property\n",
    "assert abs(mutual_information(y_true, y_pred) - mutual_information(y_pred, y_true)) == 0.,\\\n",
    "            \"Implemented MI is not symmetrical!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential mutual information\n",
    "\n",
    "#### Now consider we have predicted probabilities of labels. In this case the formula remains the same, but now $p_X(x)$ can not be calculated as $\\frac{|x|}{N}$. Instead it is calculated as $p_X(x) = \\sum_i p_i p_i(x) = \\sum_i \\frac{p_i(x)}{N} = \\mathbb{E}_i[ p_i(x) ]$ , where $p_i$ is probability of choosing point $i$, $p_i(x)$ is probability of point $i$ to be predicted as class X=x. Here to evaluate the joint distribution we calculate predicted labels as those with greater probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_dif_information(y_true: np.ndarray, predicted_probs: np.ndarray) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the mutual differential information between true labels and predicted label probabilities.\n",
    "\n",
    "    Parameters:\n",
    "    y_true (ndarray of size K): True labels.\n",
    "    y_pred (ndarray of size N * K): Predicted probabilities.\n",
    "\n",
    "    Returns:\n",
    "    float: Differential Mutual Information score.\n",
    "    \"\"\"\n",
    "    from numpy import log\n",
    "    from sklearn.metrics.cluster import contingency_matrix\n",
    "    \n",
    "    y_pred = np.argmax(predicted_probs, axis = 1)\n",
    "    p_xy = contingency_matrix(y_true, y_pred)/9\n",
    "    p_y = p_xy.sum(axis=1)\n",
    "    p_x = predicted_probs.mean(axis = 0) \n",
    "    \n",
    "    dmi = 0.0\n",
    "    for y_label in range(p_xy.shape[0]):\n",
    "        for x_label in range(p_xy.shape[1]):\n",
    "            if p_xy[y_label][x_label]: dmi += p_xy[y_label][x_label] * log(p_xy[y_label][x_label] / (p_x[x_label] * p_y[y_label]))\n",
    "\n",
    "    return dmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.array([0, 0, 1, 1, 1, 2, 2, 2, 1])\n",
    "y_true = np.array([0, 0, 1, 1, 1, 2, 2, 1, 1])\n",
    "predicted_probs = np.array([[1., 0., 0.],\n",
    "                            [1., 0., 0.],\n",
    "                            [0., 1., 0.],\n",
    "                            [0., 1., 0.],\n",
    "                            [0., 1., 0.],\n",
    "                            [0., 0., 1.],\n",
    "                            [0., 0., 1.],\n",
    "                            [0., 0., 1.],\n",
    "                            [0., 1., 0.]], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782855600747917"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_dif_information(y_true, predicted_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782855600747917"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_information(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.array([0, 0, 1, 1, 1, 2, 2, 1, 1])\n",
    "predicted_probs = np.array([[0.75, 0.20, 0.05],\n",
    "                            [0.60, 0.20, 0.20],\n",
    "                            [0.30, 0.45, 0.15],\n",
    "                            [0.25, 0.50, 0.25],\n",
    "                            [0.10, 0.50, 0.40],\n",
    "                            [0.20, 0.35, 0.45],\n",
    "                            [0.10, 0.05, 0.85],\n",
    "                            [0.10, 0.10, 0.80],\n",
    "                            [0.05, 0.90, 0.05]], dtype = float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8085289571597928"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_dif_information(y_true, predicted_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting fact - even if maximal predicted probabilities corresponds to true labels, mutual information may differ because of different $p_X(x)$ distibutions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
