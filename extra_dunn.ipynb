{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import numpy as np\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "from sklearn.utils._param_validation import (\n",
    "    StrOptions,\n",
    "    validate_params,\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import check_X_y\n",
    "from sklearn.metrics.pairwise import _VALID_METRICS, pairwise_distances_chunked\n",
    "\n",
    "\n",
    "def check_number_of_labels(n_labels, n_samples):\n",
    "    \"\"\"Check that number of labels are valid.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_labels : int\n",
    "        Number of labels.\n",
    "\n",
    "    n_samples : int\n",
    "        Number of samples.\n",
    "    \"\"\"\n",
    "    if not 1 < n_labels < n_samples:\n",
    "        raise ValueError(\n",
    "            \"Number of labels is %d. Valid values are 2 to n_samples - 1 (inclusive)\"\n",
    "            % n_labels\n",
    "        )\n",
    "\n",
    "\n",
    "def dunn_reduce(D_chunk, start, labels):\n",
    "    \"\"\"Accumulate Dunn Index score - inter- and intraclust distances for vertical chunk of X.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    D_chunk : {array-like, sparse matrix} of shape (n_chunk_samples, n_samples)\n",
    "        Precomputed distances for a chunk. If a sparse matrix is provided,\n",
    "        only CSR format is accepted.\n",
    "    start : int\n",
    "        First index in the chunk.\n",
    "    labels : array-like of shape (n_samples,)\n",
    "        Corresponding cluster labels, encoded as {0, ..., n_clusters-1}.\n",
    "    label_freqs : array-like\n",
    "        Distribution of cluster labels in ``labels``.\n",
    "    \"\"\" \n",
    "    n_chunk_samples = D_chunk.shape[0]\n",
    "\n",
    "    inter_cluster_distances = np.zeros(\n",
    "        n_chunk_samples, dtype=D_chunk.dtype\n",
    "    )\n",
    "    intra_cluster_distances = np.zeros(\n",
    "        n_chunk_samples, dtype=D_chunk.dtype\n",
    "    )\n",
    "    \n",
    "    if issparse(D_chunk):\n",
    "        if D_chunk.format != \"csr\":\n",
    "            raise TypeError(\n",
    "                \"Expected CSR matrix. Please pass sparse matrix in CSR format.\"\n",
    "            )\n",
    "        for i in range(n_chunk_samples):\n",
    "            indptr = D_chunk.indptr\n",
    "            indices = D_chunk.indices[indptr[i] : indptr[i + 1]]\n",
    "            sample_dists = D_chunk.data[indptr[i] : indptr[i + 1]]\n",
    "            sample_labels = np.take(labels, indices)\n",
    "            intra_cluster_distances[i] += np.max(\n",
    "                np.where(sample_labels == sample_labels[i],\n",
    "                         sample_dists,\n",
    "                         -np.inf)\n",
    "            )\n",
    "            inter_cluster_distances[i] += np.min(\n",
    "                np.where(sample_labels != sample_labels[i],\n",
    "                         sample_dists,\n",
    "                         np.inf)\n",
    "            )\n",
    "    else:\n",
    "        for i in range(n_chunk_samples):\n",
    "            sample_dists = D_chunk[i]\n",
    "            sample_labels = labels\n",
    "            intra_cluster_distances[i] += np.max(\n",
    "                np.where(sample_labels == sample_labels[i],\n",
    "                         sample_dists,\n",
    "                         -np.inf)\n",
    "            )\n",
    "            inter_cluster_distances[i] += np.min(\n",
    "                np.where(sample_labels != sample_labels[i],\n",
    "                         sample_dists,\n",
    "                         np.inf)\n",
    "            )\n",
    "    return intra_cluster_distances, inter_cluster_distances\n",
    "\n",
    "\n",
    "@validate_params(\n",
    "        {\n",
    "            \"X\": [\"array-like\", \"sparse matrix\"],\n",
    "            \"labels\": [\"array-like\"],\n",
    "            \"metric\" : [StrOptions(set(_VALID_METRICS) | {\"precomputed\"}), callable],\n",
    "        },\n",
    "        prefer_skip_nested_validation=True,\n",
    ")\n",
    "def dunn_index(X, labels, metric = \"euclidean\", **kwds):\n",
    "    \"\"\"Compute the Dunn Index.\n",
    "    The Intercluster distance is caclulated as the minimal between two data points, one in each cluster.\n",
    "    The Intracluster distance is caclulated as the maximal between two data points, both in the same cluster.\n",
    "    The more the value, the better.\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : {array-like, sparse matrix} of shape (n_samples_a, n_samples_a) if metric == \\\n",
    "        \"precomputed\" or (n_samples_a, n_features) otherwise\n",
    "        An array of pairwise distances between samples, or a feature array.\n",
    "\n",
    "    labels : array-like of shape (n_samples,)\n",
    "        Predicted cluster labels for each sample.\n",
    "\n",
    "    metric : str or callable, default='euclidean'\n",
    "        The metric to use when calculating distance between instances in a\n",
    "        feature array. If metric is a string, it must be one of the options\n",
    "        allowed by :func:`~sklearn.metrics.pairwise_distances`.\n",
    "    \n",
    "    **kwds : optional keyword parameters\n",
    "        Any further parameters are passed directly to the distance function.\n",
    "        If using a scipy.spatial.distance metric, the parameters are still\n",
    "        metric dependent. See the scipy docs for usage examples.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    score: float\n",
    "        The resulting Dunn Index.\n",
    "    \"\"\"\n",
    "    X, labels = check_X_y(X, labels, accept_sparse=[\"csr\"])\n",
    "\n",
    "    # Check for non-zero diagonal entries in precomputed distance matrix\n",
    "    if metric == \"precomputed\":\n",
    "        error_msg = ValueError(\n",
    "            \"The precomputed distance matrix contains non-zero \"\n",
    "            \"elements on the diagonal. Use np.fill_diagonal(X, 0).\"\n",
    "        )\n",
    "        if X.dtype.kind == \"f\":\n",
    "            atol = np.finfo(X.dtype).eps * 100\n",
    "            if np.any(np.abs(X.diagonal()) > atol):\n",
    "                raise error_msg\n",
    "        elif np.any(X.diagonal() != 0):  # integral dtype\n",
    "            raise error_msg\n",
    "    \n",
    "    \n",
    "    le = LabelEncoder()\n",
    "    labels = le.fit_transform(labels)\n",
    "    n_samples = len(labels)\n",
    "    check_number_of_labels(len(le.classes_), n_samples)\n",
    "\n",
    "    kwds[\"metric\"] = metric\n",
    "\n",
    "    reduce_func = functools.partial(\n",
    "        dunn_reduce, labels=labels\n",
    "    )\n",
    "\n",
    "    results = zip(*pairwise_distances_chunked(X, reduce_func=reduce_func, **kwds))\n",
    "    intra_clust_dists, inter_clust_dists = results\n",
    "    intra_clust_dists = np.concatenate(intra_clust_dists)   \n",
    "    inter_clust_dists = np.concatenate(inter_clust_dists)\n",
    "    return np.min(inter_clust_dists)/np.max(intra_clust_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "features, true_labels = make_blobs(\n",
    "    n_samples=200,\n",
    "    centers=3,\n",
    "    cluster_std=2.75,\n",
    "    random_state=42\n",
    "    )\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, n_init=10)\n",
    "kmeans.fit(features)\n",
    "\n",
    "random_labels = np.random.randint(0, 3, size = true_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dunn index of random labels = 0.0013 \n",
      "Dunn index of KNN labels = 0.0960\n"
     ]
    }
   ],
   "source": [
    "print(\"Dunn index of random labels = %.4f \\nDunn index of KNN labels = %.4f\" % (dunn_index(features, random_labels), dunn_index(features, kmeans.labels_)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
