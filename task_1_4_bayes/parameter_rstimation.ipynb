{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bias of Estimated Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Setting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider $n$ independant uniform random variables $X_1, \\dots, X_n \\sim U[0, \\theta]$ and find</br>\n",
    "1. Maximum Likelihood Estimation $\\theta_{ML}$ and Moment Method Estimation of $\\theta_{MM}$ </li>\n",
    "2. Maximum Posterior Estimation $\\theta_{MAP}$ if $p(\\theta) \\sim \\textit{N}(0, 1)$ \n",
    "3. Calculate Biases $\\mathbb{E}[\\theta - \\theta_{ML}]$, $\\mathbb{E}[\\theta - \\theta_{MM}]$ and $\\mathbb{E}[(\\theta - \\theta_{ML})^2]$, $\\mathbb{E}[(\\theta - \\theta_{MM})^2]$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Maximum Likelihood Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "L = \\frac{1}{\\theta^n}, \\quad \\theta < X_i \\; \\forall i\\quad \\\\\n",
    "\\; \\\\\n",
    "\\log L = -n \\log \\theta \\\\\n",
    "\\; \\\\\n",
    "\\frac{\\partial \\log L}{\\partial \\theta} = -\\frac{n}{\\theta} < 0\n",
    "$$\n",
    "\n",
    "Therefore, $L$ takes its maximal value in the minimal $\\theta$ possible, which is $X_{(n)}$:\n",
    "$$\n",
    "\\theta_{ML} = X_{(n)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Moment Method Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mathbb{E}[\\theta] = \\frac{\\theta}{2} \\Rightarrow \\theta = 2 \\mathbb{E}[\\theta] \\Rightarrow \\theta_{MM} = 2 \\overline{X} = \\frac{2}{n} \\sum_{i=1}^{n} X_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Maximum Posterior Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta_{MAP} = \\arg \\max_{\\theta} p(\\theta | D)\n",
    "$$\n",
    "\n",
    "where\n",
    "$$\n",
    "p(\\theta | D) = \\frac{p(D | \\theta) p(\\theta)}{p(D)}\n",
    "$$\n",
    "\n",
    "and since\n",
    "$$\n",
    "p(D) = \\int p(D | \\theta) p(\\theta) d\\theta\n",
    "$$\n",
    "\n",
    "is not a fucnction of $\\theta$, we have\n",
    "$$\n",
    "p(\\theta | D) \\propto p(D | \\theta) p(\\theta) = \\theta^{-n} \\frac{e^{-\\frac{\\theta^2}{2}}}{\\sqrt{2 \\pi}}, \\quad \\theta \\in [0, X_{(n)}] \\\\\n",
    "= 0, \\quad \\text{otherwise}\n",
    "$$\n",
    "\n",
    "It is clearly seen that $\\frac{\\partial p(\\theta | D)}{\\partial \\theta} < 0$. Therefore $p(\\theta | D)$ takes its maximal value in the minimal $\\theta$ possible, which is $X_{(n)}$:\n",
    "$$\n",
    "\\theta_{MAP} = X_{(n)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Bias of $\\theta_{ML}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand following calculations, consider these steps:\n",
    "1. We sample random $\\theta$ from $p(\\theta)$\n",
    "2. With this $\\theta$ we sample a dataset $D = \\{ X_1, \\dots, X_n\\}$, $X_i \\sim U[0, \\theta]$\n",
    "3. We estimate $\\theta$ as $\\theta_{ML} = X_{(n)}$ for this dataset\n",
    "Now we can repeat steps 2 and 3 over and over again and we want to know, how our estimation is biased from the real parameter. </br> </br>\n",
    "Based on these thoughts we now see that\n",
    "$$\n",
    "\\mathbb{E}[\\theta - \\theta_{ML}] = \\int (\\theta - x) p_{X_{(n)}|\\theta}(x) dx\n",
    "$$\n",
    "\n",
    "where $p_{X_{(n)}|\\theta}(x)$ is pdf of $X_{(n)}$. We know that (it is quite easy to caclulate)\n",
    "$$\n",
    "p_{X_{(n)}|\\theta}(x) = n \\frac{x^{n-1}}{\\theta^n}, \\quad \\theta \\in [0, X_{(n)}] \\\\\n",
    "= 0, \\quad otherwise\n",
    "$$\n",
    "\n",
    "Now\n",
    "$$\n",
    "\\mathbb{E}[\\theta - \\theta_{ML}] = \\int (\\theta - x) p_{X_{(n)}|\\theta}(x) dx = \\int_{0}^{\\theta} (\\theta - x) n \\frac{x^{n-1}}{\\theta^n} dx = \\frac{\\theta}{n+1}\n",
    "$$\n",
    "\n",
    "and\n",
    "$$\n",
    "\\mathbb{E}[(\\theta - \\theta_{ML})^2] = \\int (\\theta - x)^2 p_{X_{(n)}|\\theta}(x) dx = \\int_{0}^{\\theta} (\\theta - x)^2 n \\frac{x^{n-1}}{\\theta^n} dx = \\frac{2 \\theta^2}{(n+2)(n+1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Bias of $\\theta_{MM}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is a littlte trickier, because we now need $p_{2\\overline{X}|\\theta}$. There is of course Bate's distribution and Irwin-Hall distribution, but pdfs are very hard to calculate and haver recurrent dependencies, which is not suitable for calculations.</br>\n",
    "Instead, we can use Central Limit Theorem, because $\\overline{X}$ converges pretty fast. So we do it:\n",
    "$$\n",
    "F_{2\\overline{X}|theta}(z) = P(2\\overline{X} < z) = P\\bigg(\\frac{2}{n} \\sum_{i=1}^{n} X_i < z\\bigg) = //\\eta_n = \\sum_{i=1}^{n} X_i// = P\\bigg(\\frac{2}{n} \\eta_n < z\\bigg) = P \\bigg( \\frac{2}{n} \\Big(\\frac{\\eta_n - \\mu n + \\mu n}{\\sigma \\sqrt{n}} \\sigma \\sqrt{n} \\Big) < z \\bigg ) = \\\\\n",
    "\\; \\\\\n",
    "= // \\eta_n^* = \\frac{\\eta_n - \\mu n}{\\sigma \\sqrt{n}} // = P \\bigg( \\frac{2 \\sigma}{\\sqrt{n}}\\Big( \\eta_n^* + \\frac{\\mu n}{\\sigma \\sqrt{n}}\\Big)< z\\bigg) = P \\bigg( \\eta_n^* < \\frac{\\sqrt{n}}{4\\sigma} \\Big( z - 2\\theta\\Big)\\bigg) = // \\mu = \\frac{\\theta}{2}, \\sigma = \\frac{\\theta}{\\sqrt{12}} // = \\\\\n",
    "\\; \\\\\n",
    " = P \\bigg( \\eta_n^* < \\sqrt{3n} \\Big( \\frac{z}{\\theta} - 1\\Big) \\bigg) = // \\eta_n^* \\xrightarrow{\\text{dist}} \\text{N}(0, 1) // \\xrightarrow{\\text{dist}} \\Phi \\Big( \\sqrt{3n} \\big( \\frac{z}{\\theta} - 1\\big)\\Big), \\quad \\Phi(x) = \\int_{- \\inf}^{x} \\frac{e^{-\\frac{z^2}{2}}}{\\sqrt{2 \\pi}} dz\n",
    "$$\n",
    "\n",
    "Now we get pdf $p_{2\\overline{X}|\\theta}$:\n",
    "$$\n",
    "p_{2\\overline{X}|\\theta}(x) = \\frac{d {F_{2\\overline{X}|\\theta}}(x)}{dx} = \\frac{d \\Phi\\Big( \\sqrt{3n} \\big( \\frac{x}{\\theta} - 1\\big)\\Big)}{d \\Big( \\sqrt{3n} \\big( \\frac{x}{\\theta} - 1\\big)\\Big)} \\frac{d\\Big( \\sqrt{3n} \\big( \\frac{x}{\\theta} - 1\\big)\\Big)}{dx} = {\\sqrt{\\frac{3n}{2 \\pi \\theta^2}}} e^{-\\frac{-3n(x-\\theta)^2}{2\\theta^2}}\n",
    "$$\n",
    "\n",
    "which by the way means that $F_{2\\overline{X}|\\theta} \\sim N(\\theta, \\frac{\\theta}{\\sqrt{3n}})$. And with all this we can now calculate the bias\n",
    "$$\n",
    "\\mathbb{E}[\\theta - \\theta_{MM}] = \\int (\\theta - x)p_{2\\overline{X}|\\theta}(x)dx =  \\int_{-\\infty}^{+\\infty} (\\theta - x) {\\sqrt{\\frac{3n}{2 \\pi \\theta^2}}} e^{-\\frac{-3n(x-\\theta)^2}{2\\theta^2}}dx = 0\n",
    "$$\n",
    "\n",
    "as well as\n",
    "$$\n",
    "\\mathbb{E}[(\\theta - \\theta_{MM})^2] = \\int (\\theta - x)^2 p_{2\\overline{X}|\\theta}(x)dx =  \\int_{-\\infty}^{+\\infty} (\\theta - x)^2 {\\sqrt{\\frac{3n}{2 \\pi \\theta^2}}} e^{-\\frac{-3n(x-\\theta)^2}{2\\theta^2}}dx = \\frac{\\theta^2}{3n}\n",
    "$$\n",
    "\n",
    "We see that even though $\\theta_{MM}$ is an unbiased estimation of $\\theta$, it slower converges to real $\\theta$ as dataset size increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Estimation Type, $\\hat{\\theta}$ | $\\hat{\\theta}$ | $\\mathbb{E}[\\theta - \\hat{\\theta}]$ | $\\mathbb{E}[(\\theta - \\hat{\\theta})^2]$ |\n",
    "| --- | --- | --- | --- |\n",
    "| Maximum Likelihood, $\\theta_{ML}$ | $X_{(n)}$ | $\\frac{\\theta}{n+1}$ | $\\frac{2 \\theta^2}{(n+2)(n+1)}$ |\n",
    "| Moment Method $\\theta_{MM}$ | $2\\overline{X}$ | 0 | $\\frac{\\theta^2}{3n}$ |\n",
    "| Maximum Aposterior $\\theta_{MAP}$ | $X_{(n)}$ | - | - |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
